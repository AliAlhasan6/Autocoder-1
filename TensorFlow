from tensorflow.python.keras import Model
from tensorflow.python.keras.layers import Input, Conv2D, ReLU, BatchNormalization, Flatten, Dense
from tensorflow.python.keras import backend as K
# ########## in this version of tensorflow the calling of keras and methods like conv2D and ReLU is from the python.keras.layers ####
######## but the BatchNormaliztion is not there for some reason #####

class Autoencoder:

    # auto encoder represent a deep convolutional autoencoder with mirrored encoder and decoder componts.


    def __int__(self,
                input_shape,
                conv_filters,
                conv_kernels,
                conv_strides,
                latent_space_dim):

           self.input_shape = input_shape # [28, 28, 1]
           self.conv_filters = conv_filters # [2, 4, 8]
           self.conv_kernels = conv_kernels # [3, 5, 3]
           self.conv_strides = conv_strides # [1, 2, 2] # down sampling the data
           self.latent_space_dim = latent_space_dim # [2] bottel-neck 2 nerion

           self.encoder = None
           self.decoder = None
           self.model = None


           self._num_conv_layers = len(conv_filters)
           self._shape_before_bottleneck = None

           self._build()

    def summary(self):

        self.encoder.summary()


    def _build(self):
        self._build_encoder()
        self.build_decoder()
        self.build_autoencoder()


    def _build_encoder(self):
        encoder_input = self._add_encoder_input
        conv_layers = self._add_conv_layers(encoder_input)
        bottleneck = self._add_bottleneck(conv_layers)

        self.encoder = Model(encoder_input, bottleneck, name = 'encoder')


    def _add_encoder_input(self):
        return Input(shape=self.input_shape, name='encoder_input')


    def _add_conv_layers(self, encoder_input):
        #' creat all convolutional blocks in encoder.'#
      x = encoder_input # we go throught this as the number of conv layes
      for layer_index in range(self._num_conv_layers):
          x = self._add_conv_layers(layer_index, x)

          return x

    def _add_conv_layer(self, layer_index, x):
        # adds a convolutional block to a graph of layers , consisting of conv 2d + Relu + batch normalization.
        layer_number = layer_index + 1
        conv_layer = Conv2D(
            filters = self.conv_filters[layer_index],
            kernel_size = self.conv_kernels[layer_index],
            strides = self.conv_strides[layer_index],
            padding= 'same',
            name= f'encoder_conv_layer_{layer_number}'

        )
        x = conv_layer(x)
        x = ReLU(name=f'encoder_relu_{layer_number}')(x)
        x = BatchNormaliztion(name=f"encoder_bn_{layer_number}')
        return x



    def _add_bottleneck(self,x):
        'Flatten data and add bottleneck (Dense layer)'
        # store information about the shape of data before flatten it
        self._shape_before_bottleneck = k.int_shape(x)[1:] # [7,7,32]
        x = Flatten() (x)
        x = Dense() (self.latent_space_dim,name="encoder_output")
        return x


if __name__ == "__main__":
    autoencoder = Autoencoder( input_shape = (28,28,1) ,
                               conv_filtters=(32,64,64,64),
                               conv_kernels=(3,3,3,3),
                               conv_strides=(1,2,2,1),
                               latent_space_dim = 2
                              )
    autoencoder.summary()
    
